{"pages":[],"posts":[{"title":"设计模式笔记","text":"Spring中涉及的设计模式总结 简单工厂(非23种设计模式中的一种) 实现方式： BeanFactory。Spring中的BeanFactory就是简单工厂模式的体现，根据传入一个唯一的标识来获得Bean对象，但是否是在传入参数后创建还是传入参数前创建这个要根据具体情况来定。 实质： 由一个工厂类根据传入的参数，动态决定应该创建哪一个产品类。 实现原理： bean容器的启动阶段： 读取bean的xml配置文件,将bean元素分别转换成一个BeanDefinition对象。 然后通过BeanDefinitionRegistry将这些bean注册到beanFactory中，保存在它的一个ConcurrentHashMap中。 将BeanDefinition注册到了beanFactory之后，在这里Spring为我们提供了一个扩展的切口，允许我们通过实现接口BeanFactoryPostProcessor 在此处来插入我们定义的代码。典型的例子就是：PropertyPlaceholderConfigurer，我们一般在配置数据库的dataSource时使用到的占位符的值，就是它注入进去的。 容器中bean的实例化阶段： 实例化阶段主要是通过反射或者CGLIB对bean进行实例化，在这个阶段Spring又给我们暴露了很多的扩展点： 各种的Aware接口 ，比如 BeanFactoryAware，对于实现了这些Aware接口的bean，在实例化bean时Spring会帮我们注入对应的BeanFactory的实例。 BeanPostProcessor接口 ，实现了BeanPostProcessor接口的bean，在实例化bean时Spring会帮我们调用接口中的方法。 InitializingBean接口 ，实现了InitializingBean接口的bean，在实例化bean时Spring会帮我们调用接口中的方法。 DisposableBean接口 ，实现了BeanPostProcessor接口的bean，在该bean死亡时Spring会帮我们调用接口中的方法。 设计意义： 松耦合。 可以将原来硬编码的依赖，通过Spring这个beanFactory这个工厂来注入依赖，也就是说原来只有依赖方和被依赖方，现在我们引入了第三方——spring这个beanFactory，由它来解决bean之间的依赖问题，达到了松耦合的效果. bean的额外处理。 通过Spring接口的暴露，在实例化bean的阶段我们可以进行一些额外的处理，这些额外的处理只需要让bean实现对应的接口即可，那么spring就会在bean的生命周期调用我们实现的接口来处理该bean。[非常重要] 工厂方法 实现方式： FactoryBean接口。 实现原理： 实现了FactoryBean接口的bean是一类叫做factory的bean。其特点是，spring会在使用getBean() 调用获得该bean时，会自动调用该bean的getObject()方法，所以返回的不是factory这个bean，而是这个bean.getOjbect()方法的返回值。 例子： 典型的例子有spring与mybatis的结合。 代码示例： 123456&lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;property name=&quot;configLocation&quot; value=&quot;classpath:config/mybatis-config-masterxml&quot;/&gt; &lt;property name=&quot;mapperLocations&quot; value=&quot;classpath:config/mappers/master/*/xml&quot;/&gt;&lt;/bean&gt; 说明： 我们看上面该bean，因为实现了FactoryBean接口，所以返回的不是 SqlSessionFactoryBean 的实例，而是它的 SqlSessionFactoryBean.getObject() 的返回值。 单例模式 Spring依赖注入Bean实例默认是单例的。 Spring的依赖注入（包括lazy-init方式）都是发生在AbstractBeanFactory的getBean里。getBean的doGetBean方法调用getSingleton进行bean的创建。 分析getSingleton()方法 1234567891011121314151617181920212223242526272829303132public class Singleton() { public Object getSingleton(String beanName) { //参数true设置标识允许早期依赖 return getSingleton(beanName, true); } protected Object getSingleton(String beanName, boolean allowEarlyReference) { //检查缓存中是否存在实例 Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) { //如果为空，则锁定全局变量并进行处理。 synchronized (this.singletonObjects) { //如果此bean正在加载，则不处理 singletonObject = this.earlySingletonObjects.get(beanName); if (singletonObject == null &amp;&amp; allowEarlyReference) { //当某些方法需要提前初始化的时候则会调用addSingleFactory 方法将对应的ObjectFactory初始化策略存储在singletonFactories ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) { //调用预先设定的getObject方法 singletonObject = singletonFactory.getObject(); //记录在缓存中，earlySingletonObjects和singletonFactories互斥 this.earlySingletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); } } } } return (singletonObject != NULL_OBJECT ? singletonObject : null); }} getSingleton()过程图 ps：spring依赖注入时，使用了 双重判断加锁 的单例模式 123456graph TDs[[singletonObjects +getBeanName&lt;&gt;]] ==&gt;e[[earlySingletonObjects +getBeanName&lt;&gt;]] ==&gt;f[[singletonFactories +getObject&lt;&gt;]] ==&gt;创[[创建单例实例]] ===&gt;|remove|f创 ==&gt;|put|e 总结： 单例模式定义： 保证一个类仅有一个实例，并提供一个访问它的全局访问点。 spring对单例的实现： spring中的单例模式完成了后半句话，即提供了全局的访问点BeanFactory。但没有从构造器级别去控制单例，这是因为spring管理的是任意的java对象。 适配器模式 实现方式： SpringMVC中的适配器HandlerAdatper。 实现原理： HandlerAdatper根据Handler规则执行不同的Handler。 实现过程： DispatcherServlet根据HandlerMapping返回的handler，向HandlerAdatper发起请求，处理Handler。 HandlerAdapter根据规则找到对应的Handler并让其执行，执行完毕后Handler会向HandlerAdapter返回一个ModelAndView，最后由HandlerAdapter向DispatchServelet返回一个ModelAndView。 实现意义： HandlerAdatper使得Handler的扩展变得容易，只需要增加一个新的Handler和一个对应的HandlerAdapter即可。 因此Spring定义了一个适配接口，使得每一种Controller有一种对应的适配器实现类，让适配器代替controller执行相应的方法。这样在扩展Controller时，只需要增加一个适配器类就完成了SpringMVC的扩展了。 装饰器模式 实现方式： Spring中用到的包装器模式在类名上有两种表现：一种是类名中含有Wrapper，另一种是类名中含有Decorator。 实质： 动态地给一个对象添加一些额外的职责。 就增加功能来说，Decorator模式相比生成子类更为灵活。 代理模式 实现方式： AOP底层，就是动态代理模式的实现。 动态代理：在内存中构建的，不需要手动编写代理类 静态代理：需要手工编写代理类，代理类引用被代理对象。 实现原理： 切面在应用运行的时刻被织入。一般情况下，在织入切面时，AOP容器会为目标对象创建动态的创建一个代理对象。SpringAOP就是以这种方式织入切面的。 织入：把切面应用到目标对象并创建新的代理对象的过程。 观察者模式 实现方式： spring的事件驱动模型使用的是 观察者模式 ，Spring中Observer模式常用的地方是listener的实现。 具体实现： 事件机制的实现需要三个部分,事件源,事件,事件监听器 (1) ApplicationEvent抽象类[事件] 继承自jdk的EventObject,所有的事件都需要继承ApplicationEvent,并且通过构造器参数source得到事件源. 该类的实现类ApplicationContextEvent表示ApplicationContext的容器事件. 代码： 12345678910111213public abstract class ApplicationEvent extends EventObject { private static final long serialVersionUID = 7099057708183571937L; private final long timestamp; public ApplicationEvent(Object source) { super(source); this.timestamp = System.currentTimeMillis(); } public final long getTimestamp() { return this.timestamp; }} (2)ApplicationListener接口[事件监听器] 继承自jdk的EventListener,所有的监听器都要实现这个接口。 这个接口只有一个onApplicationEvent()方法,该方法接受一个ApplicationEvent或其子类对象作为参数,在方法体中,可以通过不同对Event类的判断来进行相应的处理。 当事件触发时所有的监听器都会收到消息。 代码： 123public interface ApplicationListener&lt;E extends ApplicationEvent&gt; extends EventListener { void onApplicationEvent(E event);} (3) ApplicationContext接口[事件源] ApplicationContext是spring中的全局容器，翻译过来是”应用上下文”。 实现了ApplicationEventPublisher接口。 职责：负责读取bean的配置文档,管理bean的加载,维护bean之间的依赖关系,可以说是负责bean的整个生命周期,再通俗一点就是我们平时所说的IOC容器。 代码： 123456789101112131415161718public interface ApplicationEventPublisher { void publishEvent(ApplicationEvent event);}public class EventPublisher implements ApplicationEventPublisher { public void publishEvent(ApplicationEvent event) { Assert.notNull(event, &quot;Event must not be null&quot;); if (logger.isTraceEnabled()) { logger.trace(&quot;Publishing event in &quot; + getDisplayName() + &quot;: &quot; + event); } getApplicationEventMulticaster().multicastEvent(event); if (this.parent != null) { this.parent.publishEvent(event); } }} (4)ApplicationEventMulticaster抽象类[事件源中publishEvent方法需要调用其方法getApplicationEventMulticaster] 属于事件广播器,它的作用是把ApplicationContext发布的Event广播给所有的监听器. 代码： 123456789101112131415161718public abstract class AbstractApplicationContext extends DefaultResourceLoader implements ConfigurableApplicationContext, DisposableBean { private ApplicationEventMulticaster applicationEventMulticaster; protected void registerListeners() { // Register statically specified listeners first. for (ApplicationListener&lt;?&gt; listener : getApplicationListeners()) { getApplicationEventMulticaster().addApplicationListener(listener); } // Do not initialize FactoryBeans here: We need to leave all regular beans // uninitialized to let post-processors apply to them! String[] listenerBeanNames = getBeanNamesForType(ApplicationListener.class, true, false); for (String lisName : listenerBeanNames) { getApplicationEventMulticaster().addApplicationListenerBean(lisName); } }} 策略模式 实现方式： Spring框架的资源访问Resource接口。该接口提供了更强的资源访问能力，Spring 框架本身大量使用了 Resource 接口来访问底层资源。 Resource 接口介绍 source 接口是具体资源访问策略的抽象，也是所有资源访问类所实现的接口。 Resource 接口主要提供了如下几个方法: getInputStream()： 定位并打开资源，返回资源对应的输入流。每次调用都返回新的输入流。调用者必须负责关闭输入流。 exists()： 返回 Resource 所指向的资源是否存在。 isOpen()： 返回资源文件是否打开，如果资源文件不能多次读取，每次读取结束应该显式关闭，以防止资源泄漏。 getDescription()： 返回资源的描述信息，通常用于资源处理出错时输出该信息，通常是全限定文件名或实际 URL。 getFile： 返回资源对应的 File 对象。 getURL： 返回资源对应的 URL 对象。 最后两个方法通常无须使用，仅在通过简单方式访问无法实现时，Resource 提供传统的资源访问的功能。 Resource 接口本身没有提供访问任何底层资源的实现逻辑，针对不同的底层资源，Spring 将会提供不同的 Resource 实现类，不同的实现类负责不同的资源访问逻辑。 Spring 为 Resource 接口提供了如下实现类： UrlResource： 访问网络资源的实现类。 ClassPathResource： 访问类加载路径里资源的实现类。 FileSystemResource： 访问文件系统里资源的实现类。 ServletContextResource： 访问相对于 ServletContext 路径里的资源的实现类. InputStreamResource： 访问输入流资源的实现类。 ByteArrayResource： 访问字节数组资源的实现类。 这些 Resource 实现类，针对不同的的底层资源，提供了相应的资源访问逻辑，并提供便捷的包装，以利于客户端程序的资源访问。 模版方法模式 经典模板方法定义： 父类定义了骨架（调用哪些方法及顺序），某些特定方法由子类实现。 最大的好处：代码复用，减少重复代码。除了子类要实现的特定方法，其他方法及方法调用顺序都在父类中预先写好了。 所以父类模板方法中有两类方法： 共同的方法： 所有子类都会用到的代码 不同的方法： 子类要覆盖的方法，分为两种： 抽象方法：父类中的是抽象方法，子类必须覆盖 钩子方法：父类中是一个空方法，子类继承了默认也是空的 注：为什么叫钩子，子类可以通过这个钩子（方法），控制父类，因为这个钩子实际是父类的方法（空方法）！ Spring模板方法模式实质： 是模板方法模式和回调模式的结合，是Template Method不需要继承的另一种实现方式。Spring几乎所有的外接扩展都采用这种模式。 具体实现： JDBC的抽象和对Hibernate的集成，都采用了一种理念或者处理方式，那就是模板方法模式与相应的Callback接口相结合。 采用模板方法模式是为了以一种统一而集中的方式来处理资源的获取和释放，以JdbcTemplate为例: 12345678910111213141516171819public abstract class JdbcTemplate { public final Object execute(String sql) { Connection con = null; Statement stmt = null; try { con = getConnection(); stmt = con.createStatement(); Object retValue = executeWithStatement(stmt, sql); return retValue; } catch (SQLException e) { } finally { closeStatement(stmt); releaseConnection(con); } } protected abstract Object executeWithStatement(Statement stmt, String sql);} 引入回调原因： JdbcTemplate是抽象类，不能够独立使用，我们每次进行数据访问的时候都要给出一个相应的子类实现,这样肯定不方便，所以就引入了回调。 回调代码 123public interface StatementCallback { Object doWithStatement(Statement stmt);} 利用回调方法重写JdbcTemplate方法 1234567891011121314151617181920public class JdbcTemplate { public final Object execute(StatementCallback callback) { Connection con = null; Statement stmt = null; try { con = getConnection(); stmt = con.createStatement(); Object retValue = callback.doWithStatement(stmt); return retValue; } catch (SQLException e) { } finally { closeStatement(stmt); releaseConnection(con); } }}//其它方法定义... 为什么JdbcTemplate没有使用继承？ 因为这个类的方法太多，但是我们还是想用到JdbcTemplate已有的稳定的、公用的数据库连接，那么我们怎么办呢？ 我们可以把变化的东西抽出来作为一个参数传入JdbcTemplate的方法中。但是变化的东西是一段代码，而且这段代码会用到JdbcTemplate中的变量。怎么办？ 那我们就用回调对象吧。在这个回调对象中定义一个操纵JdbcTemplate中变量的方法，我们去实现这个方法，就把变化的东西集中到这里了。然后我们再传入这个回调对象到JdbcTemplate，从而完成了调用。","link":"/2023/08/18/design-model/"},{"title":"Windows 生成及配置 GitHub SSH","text":"README 本篇主要记录Windows环境，生成及配置非默认、具有别名的SSH keys。 id_ed25519.pub 这种以默认的名称命名的公钥文件，不需要额外配置即可自动识别。 github_olive.pub 这种自定义key的公钥文件，需要在ssh-agent中添加才可被识别。 Generate SSH 1234567cd C:\\Users\\olive\\.sshssh-keygen -t ed25519 -C &quot;&lt;your github email&gt;&quot;# Generating public/private ed25519 key pair.# Enter file in which to save the key (C:\\Users\\olive/.ssh/id_ed25519): github_olivels# 2023/08/16 15:43 411 github_olive# 2023/08/16 15:43 98 github_olive.pub Github 配置 SSH keys Setting -&gt; SSH and GPG keys -&gt; New SSH key 本地测试是否配置成功 12ssh -T &quot;git@github.com&quot;# git@github.com: Permission denied (publickey). 具体原因看README。 配置 Config 文件 ssh-agent &amp; ssh-add 我实践配置只在当前窗口生效， $ eval “$(ssh-agent -s)” Agent pid 555 ssh-add ~/.ssh/github_olive 所以目前选择配置 SSH Config 文件 config 文件位置及内容如下 12345678910cd C:\\Users\\olive\\.sshls# 2023/08/16 15:43 1 config# 2023/08/16 15:43 411 github_olive# 2023/08/16 15:43 98 github_olive.pubvim config# Host github.com# HostName github.com# PreferredAuthentications publickey# IdentityFile ~/.ssh/github_olive 再次测试是否授权 12ssh -T &quot;git@github.com&quot;# Hi olive! You've successfully authenticated, but GitHub does not provide shell access.","link":"/2023/08/16/github-ssh/"},{"title":"Docker 笔记","text":"README 本篇主要记录Docker学习笔记 docker pull $image 12345678910111213141516docker pull mysql# Using default tag: latest# latest: Pulling from library/mysql# b193354265ba: Pull complete # 分层下载 联合文件系统# 14a15c0bb358: Already exists # 分层下载 联合文件系统 可以和其他镜像共用# 02da291ad1e4: Pull complete # 9a89a1d664ee: Pull complete # a24ae6513051: Pull complete # b85424247193: Pull complete # 9a240a3b3d51: Pull complete # 8bf57120f71f: Pull complete # c64090e82a0b: Pull complete # af7c7515d542: Pull complete # Digest: sha256:c0455ac041844b5e65cd08571387fa5b50ab2a6179557fd938298cab13acf0dd # 签名# Status: Downloaded newer image for mysql:latest# docker.io/library/mysql:latest #真实地址 等价 docker pull mysql 两种进入容器的方法 进入容器内部 开启一个新终端 1docker exec -it $container /bin/bash 进入容器内部 进入正在执行的容器终端 不开启新终端 1docker attach $container 拷贝文件 1docker cp $container:$path $path 拷贝容器内文件到主机 运行挂载容器卷 1docker run -it -v $name:/etc/nginx:ro nginx --volumes-from mysql 具名挂载：默认目录 /var/lib/docker/volumes/$name/_data 匿名挂载：不填$name: :ro readonly 只能容器外部修改 :rw readwrite --volumes-from 跟随挂载 例子可以实现多个mysql容器数据同步 docker inspect $container 信息 docker history $image 查看镜像历史构建步骤 Dockerfile 命令 说明 ADD 添加文件进去 COPY 添加文件进去 RUN 镜像构建时运行的命令 CMD 容器启动时运行的命令，会被外部参数替换 ENTRYPOINT 容器启动时运行的命令，可以追加 ENV 构建时设置环境变量 CMD 和 ENTRYPOINT 区别 两者都是设置某容器启动时要执行的命令 举例如下： 构建 centos 镜像，打印当前目录 123# DockerfileFROM centosCMD [&quot;ls&quot;,&quot;-a&quot;] 12docker build .docker run $container -l CMD 会报错，因为 ls -a 被替换成了 -l ENTRYPOINT 无报错，可以正常打印当前目录信息，因为 ls -a 被追加成了 ls -la Dockerfile 例子 12345678910FROM python:3.7-alpineWORKDIR /codeENV FLASK_APP=app.pyENV FLASK_RUN_HOST=0.0.0.0RUN apk add --no-cache gcc musl-dev linux-headersCOPY requirements.txt requirements.txtRUN pip install -r requirements.txtEXPOSE 5000COPY . .CMD [&quot;flask&quot;, &quot;run&quot;] 网络 容器互联 --link 只是在host中添加配置，不推荐使用。 123456docker run -d -P --name centos01 --link centos02 centosdocker run -d -P --name centos02 centos# Ping 成功docker exec -it centos01 ping centos02# Ping 失败 因为02 host 中没配置01的信息docker exec -it centos02 ping centos01 自定义网络 12345docker network create --driver=bridge --subnet=192.168.0.0/16 --gateway=192.168.0.1 my-netdocker run -d -P --name=centos01 --net=mynet centosdocker run -d -P --name=centos02 --net=mynet centos# 自定义网络可以直接ping名字，不需要--linkdocker exec -it centos01 ping centos02 自定义网络中每个节点关系已经自动维护好了。 不同的集群，比如redis集群或者mysql集群，使用不同的自定义网络，互相隔离开来。 网络联通 123# 将centos01放到my-net下# 一个容器两个ipdocker network connect my-net centos01 Compose 安装 123456# 下载curl -L https://get.daocloud.io/docker/compose/releases/download/1.26.2/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose# 授权chmod +x /usr/local/bin/docker-compose# vdocker-compose version 命令 1234# updocker-compose up -d# downdocker-compose down 样例 12345678910111213141516171819202122232425262728293031version: &quot;3&quot;services: db: image: mysql:5.7 volumes: # 挂载 - db_data:/var/lib/mysql restart: always environment: MYSQL_ROOT_PASSWORD: somewordpress # root用户 的 密码 MYSQL_DATABASE: wordpress # 数据库名 MYSQL_USER: wordpress # 数据库用户 MYSQL_PASSWORD: wordpress # 数据库密码 wordpress: depends_on: # 依赖项 - db image: wordpress:latest volumes: - wordpress_data:/var/www/html ports: - &quot;8000:80&quot; restart: always environment: WORDPRESS_DB_HOST: db WORDPRESS_DB_USER: wordpress WORDPRESS_DB_PASSWORD: wordpress WORDPRESS_DB_NAME: wordpressvolumes: db_data: { } wordpress_data: { } Swarm 准备四台服务器 简化版K8S 设置主节点 1docker swarm init --advertise-addr 192.168.64.134 生成令牌 1234# 生成管理节点的令牌docker swarm join-token manager# 生成工作节点的令牌docker swarm join-token worker 设置工作节点 1234# 135docker swarm join --token SWMTKN-1-56fs1oaww5jkhsq7f3v2f3fazgm1jgxrvjc1n4cttab8v6bmr8-04efiil88xkppw186vk82y5f1 192.168.64.135:2377# 136docker swarm join --token SWMTKN-1-56fs1oaww5jkhsq7f3v2f3fazgm1jgxrvjc1n4cttab8v6bmr8-04efiil88xkppw186vk82y5f1 192.168.64.136:2377 设置管理节点 12# 137docker swarm join --token SWMTKN-1-56fs1oaww5jkhsq7f3v2f3fazgm1jgxrvjc1n4cttab8v6bmr8-4bocoqdhfypuppql3yqxt0u2p 192.168.64.134:2377 查看所有节点 123456[root@192 ~]# docker node ls# ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSION# n2ws0fm7fvsiniuo9wjmq3dfh * 192.168.64.134 Ready Active Leader 20.10.12# y1clyylemoiqbrquha4hpgdg7 192.168.64.135 Ready Active 20.10.12# 29g0dvdvrtajsxr5d6lgutddr 192.168.64.136 Ready Active 20.10.12# mbtufs92q1q1kbsrdkfh3gx7s 192.168.64.137 Ready Active Reachable 20.10.12 Raft协议 Raft协议：保证大多数节点存活才可用 三个管理器的集群最多可以容忍一个节点的丢失。 五个管理器的集群可以容忍最大同时丢失两个节点。 N个管理器集群最多可以容忍丢失(N-1)/2个节点。 Docker 建议一个集群有七个节点。 创建服务 1234docker service create -p 80:80 nginxdocker service ls# ID NAME MODE REPLICAS IMAGE PORTS# cccvbtrm38lt nginx replicated 1/1 nginx:latest *:8888-&gt;80/tcp 动态扩容 12345678# docker service scale nginx=3 docker service update --replicas 3 nginx# nginx# overall progress: 3 out of 3 tasks # 1/3: running # 2/3: running # 3/3: running # verify: Service converged 动态缩容 1docker service scale nginx=1","link":"/2023/08/18/docker/"},{"title":"Jsoup Java 爬虫","text":"README 本篇主要记录Jsoup学习笔记 123456789101112131415161718192021222324public static void main(String[] args) throws IOException { String url = &quot;https://search.jd.com/Search?keyword=java&quot;; Document document = Jsoup.parse(new URL(url), 3000); Element element = document.getElementById(&quot;J_goodsList&quot;); if (element != null) { Elements lis = element.getElementsByTag(&quot;li&quot;); for (Element li : lis) { //图片懒加载 取src取不到的 String img = li.getElementsByTag(&quot;img&quot;).attr(&quot;data-lazy-img&quot;); System.out.println(img); } }}//println://img11.360buyimg.com/n7/jfs/t1/82473/36/24163/66491/64ad137eF3177ad97/d4bc56fe5f0de60b.jpg//img12.360buyimg.com/n7/jfs/t1/93147/2/36396/122771/64d30740F04ca7fbb/0563559dd3991401.jpg//img11.360buyimg.com/n7/jfs/t1/165807/14/35043/57871/64a65941F7c41f21c/580193f21ab25f4a.jpg//img14.360buyimg.com/n7/jfs/t1/143580/7/37074/72892/64bc9332Fe4305497/28c5bc4a54950f8d.jpg//img12.360buyimg.com/n7/jfs/t1/173641/3/39545/79502/64d30008Fe05efef3/49c4b51506410cd0.jpg//img14.360buyimg.com/n7/jfs/t1/93147/2/36396/122771/64d30740F04ca7fbb/0563559dd3991401.jpg//img14.360buyimg.com/n7/jfs/t1/4484/1l/21825/65279/6455f622F2d1b9860/d0551b7453604c15.jpg//img13.360buyimg.com/n7/jfs/t1/110197/24/37538/237025/6402328eF64f34394/0118b7bfd3f661b8.jpg//img13.360buyimg.com/n7/jfs/t1/123613/39/34171/61413/64bc9564F02d8e3a2/1b41a57175756482.jpg//img12.360buyimg.com/n7/jfs/t1/189387/15/35208/73395/64b26ccfF370691bc/4c786d4342bfcdcd.jpg","link":"/2023/08/22/jsoup/"},{"title":"Spring AOP 笔记","text":"README AOP 的使用，基本上都会涉及到自定义注解，一种非常常见的组合，就是自定义注解+AOP。 在开发中，AOP最大的作用就是重复代码简化。 首先，自定义一个注解。 定义 AOP 切面，在切面中，定义切点和通知，切点，也就是方法的拦截规则，我们可以按照注解来拦截，也就是某一个带有自定义注解的方法，将被我拦截下来。 拦截下来之后，前置通知、后置通知、异常通知、返回通知还是环绕通知。 幂等性处理 Token 机制 去重表 利用 Redis setnx 设置状态字段 上锁 自定义注解。 自定义切点。 定义环绕通知，在环绕通知中，先通过上述五种思路中的任意一种，对方法执行的幂等性进行判断。 接口限流 推荐成熟方案 Alibaba Sentinel 思路大致如下： 自定义注解。 在需要进行限流的接口方法上添加自定义注解，同时还可以设置一些限流的参数，例如时间窗口值、流量大小等。 自定义切点，拦截到方法之后，在环绕通知中，可以通过 Redis 插件 redis-cell、通过漏斗算法去处理限流。 日志处理 AOP经典例子 多数据源处理 自定义多数据源： 从 Spring2.0.1 中引入了 AbstractRoutingDataSource 类，该类充当了 DataSource 的路由中介，它能够在运行时, 根据某种 key 值来动态切换到真正的 DataSource 上。 大致的用法是提前准备好各种数据源，存入到一个 Map 中，Map 的 key 就是这个数据源的名字，Map 的 value 就是这个具体的数据源，然后再把这个 Map 配置到 AbstractRoutingDataSource 中，之后，每次执行数据库查询的时候，拿一个 key 出来，AbstractRoutingDataSource 会找到具体的数据源去执行这次数据库操作。 思路大致如下： 自定义注解。 在需要切换数据源的方法上添加自定义注解。 自定义切点，拦截到方法之后，在环绕通知中，根据注解中的配置，重新设置要执行的数据源。 方法权限处理 推荐成熟方案 Spring Security 思路大致如下： 自定义注解。 在需要进行校验的方法上添加自定义注解。 自定义切点，拦截到方法之后，在环绕通知中，根据注解中的配置，查询处理权限。 事务处理 Spring 提供注解，对于声明式事务，直接用现成的注解，本质上也是 AOP。","link":"/2023/08/18/spring-aop/"},{"title":"Windows环境VM中安装Ubuntu 23.04","text":"准备镜像 https://mirrors.tuna.tsinghua.edu.cn/ ubuntu-23.04-desktop-amd64.iso 安装VM17 MC60H-DWHD5-H80U9-6V85M-8280D VM中安装Ubuntu https://blog.csdn.net/qyfx123456/article/details/130190155 12#（vm中复制粘贴用）sudo apt-get install open-vm-tools-desktop -y Ubuntu中安装Docker https://docs.docker.com/engine/install/ubuntu/ Ubuntu中安装JDK8 1sudo apt-get install openjdk-8-jdk Ubuntu中安装Redis 安装 https://developer.aliyun.com/article/764565 1sudo apt install redis-server 注释bind 12vim /etc/redis/redis.conf# bind 127.0.0.1 设置密码 12vim /etc/redis/redis.conf# requierpass 123 通过防火墙 1sudo ufw allow proto tcp from 192.168.58.1/24 to any port 6379 开机自启动 1sudo systemctl enable redis-server Ubuntu中安装MySQL 123456789101112131415sudo apt install mysql-server# 防火墙 allowsudo ufw allow mysqlsudo vim /etc/mysql/mysql.conf.d/mysqld.cnfbind-address 0.0.0.0# mysqlmysqluse mysql;set global validate_password.policy=0;set global validate_password.length=3;ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY '123456';update user set host = '%' where user='root';FLUSH PRIVILEGES;# restartsudo systemctl restart mysql Docker中安装Nacos 123456789vim Dokcerfile# DockerfileFROM nacos/nacos-server:latestEXPOSE 8848ENV MODE standaloneENV LANG en_US.UTF-8ENV LANGUAGE en_US.UTF-8ENV LC_ALL en_US.UTF-8CMD [&quot;nacos&quot;] 12# builddocker build -t nacos . 12# rundocker run --name nacos --restart=always -d -p 8848:8848 nacos 12# ufwsudo ufw allow proto tcp from 192.168.58.1/24 to any port 8848 12# curlcurl localhost:8848/nacos","link":"/2023/08/18/vm-ubuntu/"},{"title":"通过 GitHub 搭建个人博客 Hexo","text":"README https://hexo.io/zh-cn/ 安装之前确认好要安装的 Hexo 版本所对应的 Node 最低需求 例如 Hexo 6.3.0 最低支持 node 14 构建 https://www.npmjs.com/package/hexo/v/6.3.0 安装 Hexo 1npm install -g hexo-cli 建站 123hexo init &lt;folder&gt;cd &lt;folder&gt;npm install 本地运行 123hexo cleanhexo ghexo s 访问 localhost:4000 部署 部署到 GitHub Pages 修改 _config.yml 替换添加如下 1234deploy: type: git repo: git@github.com:$username/$username.github.io.git branch: master 1npm install hexo-deployer-git --save 最后执行三连。 123hexo cleanhexo ghexo d 访问 $username.github.io 仓库名称需要设置成 $username.github.io 的格式","link":"/2023/08/16/hexo-init/"},{"title":"泛型擦除","text":"以下文章来源于码农参上 ，作者Dr Hydra 码农参上.专注后端技术分享，有趣、深入、直接，与你聊聊技术。 先看一道常见的面试题，下面的代码的执行结果是什么？ 12345public static void main(String[] args) { List&lt;String&gt; list1=new ArrayList&lt;String&gt;(); List&lt;Integer&gt; list2=new ArrayList&lt;Integer&gt;(); System.out.println(list1.getClass()==list2.getClass());} 首先，我们知道getClas方法获取的是对象运行时的类（Class），那么这个问题也就可以转化为ArrayList&lt;String&gt;和ArrayList&lt;Integer&gt;的对象在运行时对应的Class是否相同？ 我们直接揭晓答案，运行上面的代码，程序会打印true，说明虽然在代码中声明了具体的泛型，但是两个List对象对应的Class是一样的，对它们的类型进行打印，结果都是： 1class java.util.ArrayList 也就是说，虽然ArrayList&lt;String&gt;和ArrayList&lt;Integer&gt;在编译时是不同的类型，但是在编译完成后都被编译器简化成了ArrayList，这一现象，被称为泛型的类型擦除(Type Erasure)。泛型的本质是参数化类型，而类型擦除使得类型参数只存在于编译期，在运行时，jvm是并不知道泛型的存在的。 那么为什么要进行泛型的类型擦除呢？查阅的一些资料中，解释说类型擦除的主要目的是避免过多的创建类而造成的运行时的过度消耗。试想一下，如果用List&lt;A&gt;表示一个类型，再用List&lt;B&gt;表示另一个类型，以此类推，无疑会引起类型的数量爆炸。 在对类型擦除有了一个大致的了解后，我们再看看下面的几个问题。 类型擦除做了什么？ 上面我们说了，编译完成后会对泛型进行类型擦除，如果想要眼见为实，实际看一下的话应该怎么办呢？那么就需要对编译后的字节码文件进行反编译了，这里使用一个轻量级的小工具Jad来进行反编译（可以从这个地址进行下载：https://varaneckas.com/jad/） Jad的使用也很简单，下载解压后，把需要反编译的字节码文件放在目录下，然后在命令行里执行下面的命令就可以在同目录下生成反编译后的.java文件了： 1jad -sjava Test.class 好了，工具准备好了，下面我们就看一下不同情况下的类型擦除。 1、无限制类型擦除 当类定义中的类型参数没有任何限制时，在类型擦除后，会被直接替换为Object。在下面的例子中，&lt;T&gt;中的类型参数T就全被替换为了Object（左侧为编译前的代码，右侧为通过字节码文件反编译得到的代码）： 2、有限制类型擦除 当类定义中的类型参数存在限制时，在类型擦除中替换为类型参数的上界或者下界。下面的代码中，经过擦除后T被替换成了Integer： 3、擦除方法中的类型参数 比较下面两边的代码，可以看到在擦除方法中的类型参数时，和擦除类定义中的类型参数一致，无限制时直接擦除为Object，有限制时则会被擦除为上界或下界： 反射能获取泛型的类型吗？ 估计对Java反射比较熟悉小伙伴要有疑问了，反射中的getTypeParameters方法可以获得类、数组、接口等实体的类型参数，如果类型被擦除了，那么能获取到什么呢？我们来尝试一下使用反射来获取类型参数： 1System.out.println(Arrays.asList(list1.getClass().getTypeParameters())); 执行结果如下： 1[E] 同样，如果打印Map对象的参数类型： 12Map&lt;String,Integer&gt; map=new HashMap&lt;&gt;();System.out.println(Arrays.asList(map.getClass().getTypeParameters())); 最终也只能够获取到： 1[K, V] 可以看到通过getTypeParameters方法只能获取到泛型的参数占位符，而不能获得代码中真正的泛型类型。 能在指定类型的List中放入其他类型的对象吗？ 使用泛型的好处之一，就是在编译的时候能够检查类型安全，但是通过上面的例子，我们知道运行时是没有泛型约束的，那么是不是就意味着，在运行时可以把一个类型的对象能放进另一类型的List呢？我们先看看正常情况下，直接调用add方法会有什么报错： 当我们尝试将User类型的对象放入String类型的数组时，泛型的约束会在编译期间就进行报错，提示提供的User类型对象不适用于String类型数组。那么既然编译时不行，那么我们就在运行时写入，借助真正运行的class是没有泛型约束这一特性，使用反射在运行时写入： 12345678910111213141516public class ReflectTest { static List&lt;String&gt; list = new ArrayList&lt;&gt;(); public static void main(String[] args) { list.add(&quot;1&quot;); ReflectTest reflectTest =new ReflectTest(); try { Field field = ReflectTest.class.getDeclaredField(&quot;list&quot;); field.setAccessible(true); List list=(List) field.get(reflectTest); list.add(new User()); } catch (Exception e) { e.printStackTrace(); } }} 执行上面的代码，不仅在编译期间可以通过语法检查，并且也可以正常地运行，我们使用debug来看一下数组中的内容： 可以看到虽然数组中声明的泛型类型是String，但是仍然成功的放入了User类型的对象。那么，如果我们在代码中尝试取出这个User对象，程序还能正常执行吗，我们在上面代码的最后再加上一句： 1System.out.println(list.get(1)); 再次执行代码，程序运行到最后的打印语句时，报错如下： 异常提示User类型的对象无法被转换成String类型，这是否也就意味着，在取出对象时存在强制类型转换呢？我们来看一下ArrayList中get方法的源码： 12345678public E get(int index) { rangeCheck(index); return elementData(index);}E elementData(int index) { return (E) elementData[index];} 可以看到，在取出元素时，会将这个元素强制类型转换成泛型中的类型，也就是说在上面的代码中，最后会尝试强制把User对象转换成String类型，在这一阶段程序会报错。通过这一过程，也再次证明了泛型可以对类型安全进行检测。 类型擦除会引起什么问题？ 下面我们看一个稍微有点复杂的例子，首先声明一个接口，然后创建一个实现该接口的类： 12345678910public interface Fruit&lt;T&gt; { T get(T param);}public class Apple implements Fruit&lt;Integer&gt; { @Override public Integer get(Integer param) { return param; }} 按照之前我们的理解，在进行类型擦除后，应该是这样的： 12345678910public interface Fruit { Object get(Object param);}public class Apple implements Fruit { @Override public Integer get(Integer param) { return param; }} 但是，如果真是这样的话那么代码是无法运行的，因为虽然Apple类中也有一个get方法，但是与接口中的方法参数不一致，也就是说没有覆盖接口中的方法。针对这种情况，编译器会通过添加一个桥接方法来满足语法上的要求，同时保证了基于泛型的多态能够有效。我们反编译上面代码生成的字节码文件： 可以看到，编译后的代码中生成了两个get方法。参数为Object的get方法负责实现Fruit接口中的同名方法，然后在实现类中又额外添加了一个参数为Integer的get方法，这个方法也就是理论上应该生成的带参数类型的方法。最终用接口方法调用额外添加的方法，通过这种方式构建了接口和实现类的关系，类似于起到了桥接的作用，因此也被称为桥接方法，最终，通过这种机制保证了泛型情况下的Java多态性。 总结 本文由面试中常见的一道面试题入手，介绍了java中泛型的类型擦除相关知识，通过这一过程，也便于大家理解为什么平常总是说java中的泛型是一个伪泛型，同时也有助于大家认识到java中泛型的一些缺陷。了解类型擦除的原因以及原理，相信能够方便大家在日常的工作中更好的使用泛型。","link":"/2023/09/19/%E6%B3%9B%E5%9E%8B%E6%93%A6%E9%99%A4/"},{"title":"Redis 笔记","text":"README 本篇主要记录Redis学习笔记 测试性能 阿里云单核机器每秒处理100并发接近6W请求 123456789101112# 100个并发 100000个请求redis-benchmark -h localhost -p 6379 -c 100 -n 100000# 100000 requests completed in 1.68s seconds# 100 parallel clients# 3 bytes payload# keep alive: 1# 28.46% &lt;= 1 milliseconds# 98.63% &lt;= 2 milliseconds# 100.00% &lt;= 2 milliseconds# 28.46% &lt;= 1 milliseconds# 58374.34 requests per second 字符串 string set msg &quot;hello world&quot; 命令 描述 示例 append key value 向指定的 key 的 value 后追加字符串 incr / decr key 将指定 key 的 value 数值进行 +1 / -1 incrby / decrby key n 按指定的步长对数值进行加减 incrbyfloat key n 为数值加上浮点型数值 strlen key 获取 key 保存值的字符串长度 getrange key start end 按起止位置获取字符串 getrange msg 3 9 &gt; “lo worl” setrange key offset value 用指定的 value 替换 key 中 offset 开始的值 setrange msg 2 hello &gt; “hehello” getset key value 将给定 key 的值设为 value 并返回 old value getset msg xxx &gt; “hello world” setnx key value 仅当key不存在时进行set setex key seconds value set 键值对并设置过期时间 mset key1 value1 [key2 value2…] 批量set键值对 msetnx key1 value1 [key2 value2…] 批量设置键值对，仅当参数中所有的key都不存在时执行 mget key1 [key2…] 批量获取多个key保存的值 psetex key milliseconds value set 键值对并设置毫秒过期时间 列表 list 按照插入顺序排序 最大的成员数为 2^32 - 1，4294967295，40多亿 命令 描述 lpush / rpush key value… 从 头 / 尾 向 list 中 push 值，返回结果列表 length lrange key start end 获取列表 起 止 元素 lpushx / rpushx key value… 向已存在的列表中 push 值 linsert key before / after pivot value 在指定列表元素的 前 / 后 insert 值 llen key 查看列表长度 lindex key index 通过索引获取列表元素 lset key index value 通过索引为元素设值 lpop / rpop key 从 头 / 尾 移除值并返回 rpoplpush source destination 将列表的尾部值弹出并返回，然后加到另一个列表的头部 ltrim key start end 通过下标截取指定范围内的列表 lrem key count value count &gt; 0：从头开始搜索，删除指定值，至多删除count个 count &lt; 0：从尾开始搜索，删除指定值，至多删除count个 count = 0：删除列表中所有指定值。 blpop / brpop list… timeout 移出并获取列表的 头 / 尾 ， 如果列表没有元素会阻塞列表直到超时或发现可弹出元素 brpoplpush source destination timeout 将列表的尾部值并返回，然后加到另一个列表的头部如果列表没有元素会阻塞列表直到超时或发现可弹出元素 集合 set 是 string 的无序集合，集合成员是唯一的 是通过哈希表实现的，添加、删除、查找复杂度都是O(1) 最大的成员数为 2^32 - 1，4294967295，40多亿 命令 描述 sadd key value… 向集合中无序添加成员 scard key 获取集合的成员数 smembers key 返回集合中所有的成员 srandmember key [count] 随机返回集合中count个成员，count缺省值为1 spop key [count] 随机移除并返回集合中count个成员，count缺省值为1 smove source destination value 将源集合的成员移动到目标集合 srem key value… 移除集合中的成员 sdiff key key… 获取第一个集合中独有的元素 sdiffstore destination key key… 获取第一个集合中独有的元素保存覆盖到目标集合 sinter key… 返回所有集合的交集 sinterstore destination key key… 返回所有集合的交集保存覆盖到目标集合 sunion key key… 返回所有集合的并集 sunionstore destination key key… 返回所有集合的并集保存覆盖到目标集合 sscan key [MATCH pattern] [COUNT count] 遍历集合中元素 哈希表 hash key - Map&lt;field,value&gt; 是一个 string 类型的 field 和 value 的映射表 命令 描述 hset key field value hmset key [field value]… hsetnx key field value 当 field 不存在时，设置值 hexists key field 查看哈希表中指定的字段是否存在 hget key field value hmget key field… 获取所有给定字段的值 hgetall key hkeys key hlen key hvals key hdel key field… hincrby key field n 为指定字段的整数值加n，并返回增量后结果 hincrbyfloat key field n 为指定字段的浮点值加n，并返回增量后结果 hscan key cursor [MATCH pattern] [COUNT count] 遍历 有序集合 zset 每个成员关联一个double类型的分数，通过分数来为集合中的成员进行默认正序排序。 分数相同情况按字典顺序排序 有序集合的成员是唯一的，但score可以重复。 命令 描述 zadd key [source value] 集合添加一个或多个成员，或者更新已存在成员分数 zcard key 获取集合的成员数 zcount key min max 计算集合中指定分数区间的成员数 zincrby key n value 集合中对指定成员的分数加上n zscore key value 返回集合中指定成员的分数 zrank key value 返回集合中指定成员的索引 zrange key start end 通过索引区间返回集合成指定区间内的成员 zrangelbylex key start end 通过字典区间返回集合的成员 zrangebyscore key start end 通过分数区间返回集合的成员 zlexcount key start end 计算集合中指定字典区间内成员数量 zrem key value… zremrangebylex key start end 移除集合中给定的字典区间的所有成员 zremrangebyrank key start end 移除集合中给定的排名区间的所有成员 zremrangebyscore key start end 移除集合中给定的分数区间的所有成员 zrevrange key start end 返回集合中指定索引区间内的成员，倒序排序 zrevrangebyscore key start end 返回集合中指定分数区间内的成员，倒序排序 zrevrangebylex key start end 返回集合中指定字典区间内的成员，倒序排序 zrevrank key value 返回集合中指定分数区间内的成员，倒序排序 zinterstore destination numkeys key… 计算给定的一个或多个有序集的交集，其中给定 key 的数量必须以 numkeys 参数指定，并将该交集(结果集)储存到 destination zunionstore destination numkeys key… zscan key cursor [MATCH pattern] [COUNT count] 遍历 地理位置 使用经纬度定位地理坐标并用一个有序集合zset保存 m 表示单位为米。 km 表示单位为千米。 mi 表示单位为英里。 ft 表示单位为英尺。 withcoord：带上坐标 withdist：带上距离，单位与半径单位相同 geoadd key [longitude latitude member]… geopos key member… 获取成员 geodist key member1 member2 unit 返回两个给定位置之间的距离，默认米 georadius key longitude latitude radius unit [WITHCOORD] [WITHDIST] [COUNT count] [ASC|DESC] [STORE key] [STOREDIST key] 以给定的经纬度为中心， 返回集合包含的位置元素当中， 与中心的距离不超过给定最大距离的所有成员 georadiusbymember key member radius 功能与GEORADIUS相同，只是中心位置不是具体的经纬度，而是使用结合中已有的成员作为中心点 基数 hyperloglog HyperLogLog 是用来做基数统计的算法，HyperLogLog在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的、并且是很小的。 花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基数。 因为 HyperLogLog只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。 其底层使用string数据类型 命令 描述 pfadd key element… pfcount key… pfmerge destkey sourcekey… 位图 bitmap 使用位存储，信息状态只有 0 和 1。 Bitmap是一串连续的2进制数字（0或1），每一位所在的位置为偏移(offset)，在bitmap上可执行AND,OR,XOR,NOT以及其它位操作。 其底层使用string数据类型 命令 描述 setbit key offset value 为指定key的offset位设置 0 / 1 getbit key offset bitcount key [start end] 统计字符串被设置为1的bit数 bitop operration destkey key… 对一个或多个保存二进制位的字符串 key 进行位元操作，并将结果保存到 destkey 上 bitpos key bit [start] [end] 返回字符串里面第一个被设置为1或者0的bit位，start和end只能按字节，不能按位 事务 Redis 事务不保证原子性 事务流程 开启事务（multi） 命令入队 执行事务（exec） 取消事务 (discurd) 事务错误 代码语法错误（编译时异常）所有的命令都不执行 代码逻辑错误（运行时异常）其他命令可以正常执行 加锁 乐观锁 加锁 watch key 解锁 unwatch key 监控到数据不一致 exec 执行会失败 持久化 RDB redis database 占用内存空间大，数据完整性低 Snapshot 快照 Redis 默认开启 AOF append only file 恢复优先级高、恢复速度快、io性能影响大、数据完整性高（主要根据策略决定） 类似binlog，记录所有操作 Redis 默认不开启 总结 如果没有硬性数据完整性要求，建议不开启AOF，同时只在Slave上使用RDB，只保留save 900 1这一条，15分钟备份一次即可 主从复制 只需要配置从机 命令 slaveof host port 配置文件 replicaof host port 从机启动后必定会进行一次全量复制 主机每次写操作都会进行一次增量复制到从机 哨兵模式 sentinel monitor myredis host port 1","link":"/2023/08/22/redis/"}],"tags":[{"name":"设计模式","slug":"设计模式","link":"/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"GitHub","slug":"GitHub","link":"/tags/GitHub/"},{"name":"Git","slug":"Git","link":"/tags/Git/"},{"name":"SSH","slug":"SSH","link":"/tags/SSH/"},{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"Spider","slug":"Spider","link":"/tags/Spider/"},{"name":"Jsoup","slug":"Jsoup","link":"/tags/Jsoup/"},{"name":"Spring AOP","slug":"Spring-AOP","link":"/tags/Spring-AOP/"},{"name":"Ubuntu","slug":"Ubuntu","link":"/tags/Ubuntu/"},{"name":"VM","slug":"VM","link":"/tags/VM/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"泛型","slug":"泛型","link":"/tags/%E6%B3%9B%E5%9E%8B/"},{"name":"Redis","slug":"Redis","link":"/tags/Redis/"}],"categories":[{"name":"设计模式","slug":"设计模式","link":"/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"SSH","slug":"SSH","link":"/categories/SSH/"},{"name":"Docker","slug":"Docker","link":"/categories/Docker/"},{"name":"Spider","slug":"Spider","link":"/categories/Spider/"},{"name":"Spring AOP","slug":"Spring-AOP","link":"/categories/Spring-AOP/"},{"name":"Ubuntu","slug":"Ubuntu","link":"/categories/Ubuntu/"},{"name":"Hexo","slug":"Hexo","link":"/categories/Hexo/"},{"name":"泛型","slug":"泛型","link":"/categories/%E6%B3%9B%E5%9E%8B/"},{"name":"VM","slug":"Ubuntu/VM","link":"/categories/Ubuntu/VM/"},{"name":"Redis","slug":"Redis","link":"/categories/Redis/"}]}